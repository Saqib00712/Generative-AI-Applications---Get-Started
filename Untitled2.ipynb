{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "438f02b9-ad2e-4024-804d-a0fe67322861",
   "metadata": {},
   "source": [
    "Overview\n",
    "\n",
    "üß† Prompt Engineering Overview\n",
    "Welcome to the world of Prompt Engineering ‚Äî where every instruction you design has the power to guide intelligent LLM systems toward precise, meaningful outcomes.\n",
    "\n",
    "üåü What You Will Learn\n",
    "In this tutorial, you will explore the core foundations and advanced techniques of prompt engineering, including:\n",
    "\n",
    "üîπ Foundational Concepts\n",
    "How to write clear, effective prompts\n",
    "How prompts influence LLM behavior and output\n",
    "Best practices for structuring instructions\n",
    "üîπ Advanced In-Context Learning Techniques\n",
    "Few-shot prompting\n",
    "Self-consistent reasoning\n",
    "Enhanced context control\n",
    "Using examples to guide model behavior\n",
    "üîπ LangChain Prompt Templates\n",
    "You will discover how LangChain:\n",
    "\n",
    "Simplifies prompt construction\n",
    "Helps create reusable, dynamic templates\n",
    "Makes prompting more structured, consistent, and scalable\n",
    "üöÄ What You Will Build\n",
    "By applying these prompt engineering skills, you will learn to create real-world AI applications such as:\n",
    "\n",
    "‚úîÔ∏è Question-Answering (QA) Bots\n",
    "Use structured prompts to extract accurate answers\n",
    "Control tone, depth, and style of responses\n",
    "‚úîÔ∏è Text Summarization Tools\n",
    "Convert long, complex text into clear summaries\n",
    "Implement template-driven summarization pipelines\n",
    "With LangChain templates, you'll transform complex requirements into clear, modular tasks for AI systems ‚Äî making development faster, smarter, and more reliable.\n",
    "\n",
    "üéØ Final Takeaway\n",
    "This tutorial equips you with everything you need to:\n",
    "\n",
    "Write better prompts\n",
    "Use structured templates\n",
    "Build smarter LLM-powered applications\n",
    "You're not just learning to prompt ‚Äî you're learning to engineer intelligent behavior.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "üéØ Objectives\n",
    "After completing this lab, you will be able to:\n",
    "\n",
    "1. üß© Understand the Basics of Prompt Engineering\n",
    "Develop a solid foundation in:\n",
    "\n",
    "How to communicate effectively with LLMs through prompts\n",
    "Structuring clear, goal-oriented instructions\n",
    "Setting the stage for advanced prompting techniques\n",
    "2. üöÄ Master Advanced Prompt Techniques\n",
    "Learn and apply advanced methods such as:\n",
    "\n",
    "Few-shot prompting\n",
    "Self-consistent learning\n",
    "Optimizing LLM responses through guided context\n",
    "3. üõ†Ô∏è Utilize LangChain Prompt Templates\n",
    "Gain proficiency in:\n",
    "\n",
    "Using LangChain‚Äôs PromptTemplate\n",
    "Structuring reusable and dynamic prompts\n",
    "Making interactions with LLMs more organized and efficient\n",
    "4. ü§ñ Develop Practical LLM Agents\n",
    "Acquire hands-on skills to build real applications:\n",
    "\n",
    "QA bots\n",
    "Text summarization tools\n",
    "Other AI agents powered by LangChain prompt templates\n",
    "Translate your theoretical understanding into practical, deployable solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be862f7-fa36-4478-8381-fe935c908cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# IBM WatsonX imports\n",
    "from ibm_watsonx_ai.foundation_models import Model\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes\n",
    "\n",
    "from langchain_ibm import WatsonxLLM\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableSequence\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.chains import LLMChain  # Still using this for backward compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24290000-6df1-41b6-a8f4-278783aca50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_model(prompt_txt, params=None):\n",
    "    \n",
    "    model_id = \"ibm/granite-3-2-8b-instruct\"\n",
    "\n",
    "    default_params = {\n",
    "        \"max_new_tokens\": 256,\n",
    "        \"min_new_tokens\": 0,\n",
    "        \"temperature\": 0.5,\n",
    "        \"top_p\": 0.2,\n",
    "        \"top_k\": 1\n",
    "    }\n",
    "\n",
    "    if params:\n",
    "        default_params.update(params)\n",
    "\n",
    "    # Set up credentials for WatsonxLLM\n",
    "    url = \"https://us-south.ml.cloud.ibm.com\"\n",
    "    api_key = \"your api key here\"\n",
    "    project_id = \"skills-network\"\n",
    "\n",
    "    credentials = {\n",
    "        \"url\": url,\n",
    "        # \"api_key\": api_key\n",
    "        # uncomment the field above and replace the api_key with your actual Watsonx API key\n",
    "    }\n",
    "    \n",
    "    # Create LLM directly\n",
    "    granite_llm = WatsonxLLM(\n",
    "        model_id=model_id,\n",
    "        credentials=credentials,\n",
    "        project_id=project_id,\n",
    "        params=default_params\n",
    "    )\n",
    "    \n",
    "    response = granite_llm.invoke(prompt_txt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1634cb6d-205f-4aee-9152-60fd233243f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_model(prompt_txt, params=None):\n",
    "    \n",
    "    model_id = \"ibm/granite-3-2-8b-instruct\"\n",
    "\n",
    "    default_params = {\n",
    "        \"max_new_tokens\": 256,\n",
    "        \"min_new_tokens\": 0,\n",
    "        \"temperature\": 0.5,\n",
    "        \"top_p\": 0.2,\n",
    "        \"top_k\": 1\n",
    "    }\n",
    "\n",
    "    url = \"https://us-south.ml.cloud.ibm.com\"\n",
    "    project_id = \"skills-network\"\n",
    "    \n",
    "    granite_llm = WatsonxLLM(\n",
    "        model_id=model_id,\n",
    "        project_id=project_id,\n",
    "        url=url,\n",
    "        params=default_params\n",
    "    )\n",
    "    \n",
    "    response = granite_llm.invoke(prompt_txt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18493f7-48b5-4a48-8588-46fc44e9f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "GenParams().get_example_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a6d5f1-3c4f-42c4-b816-1d505f601909",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
