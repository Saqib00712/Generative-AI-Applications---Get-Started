{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d3a7f6b-8573-4d3b-b0a8-3e479493d7bd",
   "metadata": {},
   "source": [
    "Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f13edb-f37c-4f2e-9902-557d15b815f3",
   "metadata": {},
   "source": [
    "# üß† Prompt Engineering Overview  \n",
    "Welcome to the world of **Prompt Engineering** ‚Äî where every instruction you design has the power to guide intelligent LLM systems toward precise, meaningful outcomes.\n",
    "\n",
    "---\n",
    "\n",
    "## üåü What You Will Learn\n",
    "In this tutorial, you will explore the **core foundations** and **advanced techniques** of prompt engineering, including:\n",
    "\n",
    "### üîπ Foundational Concepts\n",
    "- How to write clear, effective prompts  \n",
    "- How prompts influence LLM behavior and output  \n",
    "- Best practices for structuring instructions\n",
    "\n",
    "### üîπ Advanced In-Context Learning Techniques\n",
    "- **Few-shot prompting**  \n",
    "- **Self-consistent reasoning**  \n",
    "- Enhanced context control  \n",
    "- Using examples to guide model behavior\n",
    "\n",
    "### üîπ LangChain Prompt Templates\n",
    "You will discover how LangChain:\n",
    "- Simplifies prompt construction  \n",
    "- Helps create reusable, dynamic templates  \n",
    "- Makes prompting more structured, consistent, and scalable  \n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ What You Will Build\n",
    "By applying these prompt engineering skills, you will learn to create real-world AI applications such as:\n",
    "\n",
    "### ‚úîÔ∏è **Question-Answering (QA) Bots**\n",
    "- Use structured prompts to extract accurate answers  \n",
    "- Control tone, depth, and style of responses  \n",
    "\n",
    "### ‚úîÔ∏è **Text Summarization Tools**\n",
    "- Convert long, complex text into clear summaries  \n",
    "- Implement template-driven summarization pipelines  \n",
    "\n",
    "With LangChain templates, you'll transform **complex requirements** into **clear, modular tasks** for AI systems ‚Äî making development faster, smarter, and more reliable.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Final Takeaway\n",
    "This tutorial equips you with everything you need to:\n",
    "- Write better prompts  \n",
    "- Use structured templates  \n",
    "- Build smarter LLM-powered applications  \n",
    "\n",
    "You're not just learning to prompt ‚Äî you're learning to **engineer intelligent behavior**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dffec52-21c8-4dcb-9fd3-8e3be6340151",
   "metadata": {},
   "source": [
    "# üéØ Objectives\n",
    "\n",
    "After completing this lab, you will be able to:\n",
    "\n",
    "---\n",
    "\n",
    "## 1. üß© Understand the Basics of Prompt Engineering\n",
    "Develop a solid foundation in:\n",
    "- How to communicate effectively with LLMs through prompts  \n",
    "- Structuring clear, goal-oriented instructions  \n",
    "- Setting the stage for advanced prompting techniques  \n",
    "\n",
    "---\n",
    "\n",
    "## 2. üöÄ Master Advanced Prompt Techniques\n",
    "Learn and apply advanced methods such as:\n",
    "- **Few-shot prompting**\n",
    "- **Self-consistent learning**\n",
    "- Optimizing LLM responses through guided context  \n",
    "\n",
    "---\n",
    "\n",
    "## 3. üõ†Ô∏è Utilize LangChain Prompt Templates\n",
    "Gain proficiency in:\n",
    "- Using LangChain‚Äôs `PromptTemplate`  \n",
    "- Structuring reusable and dynamic prompts  \n",
    "- Making interactions with LLMs more organized and efficient  \n",
    "\n",
    "---\n",
    "\n",
    "## 4. ü§ñ Develop Practical LLM Agents\n",
    "Acquire hands-on skills to build real applications:\n",
    "- **QA bots**\n",
    "- **Text summarization tools**\n",
    "- Other AI agents powered by LangChain prompt templates  \n",
    "\n",
    "Translate your theoretical understanding into **practical, deployable solutions**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840b2c46-e665-43f2-8531-7d7e23745d44",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è Set Up the LLM\n",
    "\n",
    "In this section, you will configure and initialize an LLM using **IBM watsonx.ai**.  \n",
    "The following code sets up the **Granite model** on the watsonx.ai platform and wraps it inside a reusable function.\n",
    "\n",
    "---\n",
    "\n",
    "## üîë Key Configuration Parameters\n",
    "\n",
    "Below is a breakdown of the main components used while initializing the model:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. üÜî `model_id`**\n",
    "Specifies **which model** you want to use.  \n",
    "- IBM watsonx.ai provides multiple foundation models.  \n",
    "- In this tutorial, you will use:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d06db1-51f4-4e13-84f2-94105b97ea1a",
   "metadata": {},
   "source": [
    "\n",
    "You can explore more options in the **Foundation Models documentation**.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. ‚öôÔ∏è `parameters`**\n",
    "Defines the **model‚Äôs configuration settings**.\n",
    "\n",
    "For this lab:\n",
    "- Five commonly used parameters are set.\n",
    "- If you want to explore more parameter options, run:\n",
    "\n",
    "```python\n",
    "GenParams().get_example_values()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570966ca-4b3a-4dff-80a2-b951f431037d",
   "metadata": {},
   "source": [
    "# üîê API Disclaimer\n",
    "\n",
    "This lab uses Large Language Models (LLMs) provided by **IBM Watsonx.ai**.  \n",
    "The environment you are using has been **pre-configured** to allow LLM usage **without requiring API keys**, so you can experiment and run prompts **for free** (within usage limitations).\n",
    "\n",
    "> ‚ö†Ô∏è **Important:**  \n",
    "> If you plan to run this notebook **locally**, outside the Skills Network JupyterLab environment, you must configure your **own API keys**.  \n",
    "> Using your own API keys means **you will incur personal usage charges** as defined by IBM‚Äôs pricing.\n",
    "\n",
    "---\n",
    "\n",
    "# üñ•Ô∏è Running the Notebook Locally\n",
    "\n",
    "If you choose to run this lab on your local machine:\n",
    "\n",
    "### ‚úîÔ∏è You must configure your Watsonx.ai API credentials.\n",
    "\n",
    "This lab uses the `WatsonxLLM` module from IBM.  \n",
    "When running locally, the `granite_llm` must be initialized **with valid credentials** so the LLM can be accessed.\n",
    "\n",
    "---\n",
    "\n",
    "## üîß How to Configure Your API Keys\n",
    "\n",
    "1. Locate the code cell in this notebook where credentials are defined.  \n",
    "2. You will see a commented-out field for:\n",
    "\n",
    "```python\n",
    "api_key = \"YOUR_API_KEY_HERE\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eaa4e7-1611-4f91-bdbe-c3728816c3f8",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939dd01b-60a9-4889-b2c3-adb95885ff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# IBM WatsonX imports\n",
    "from ibm_watsonx_ai.foundation_models import Model\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes\n",
    "\n",
    "from langchain_ibm import WatsonxLLM\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableSequence\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.chains import LLMChain  # Still using this for backward compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6846cd-e36b-45cf-a51a-840f609b7cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_model(prompt_txt, params=None):\n",
    "    \n",
    "    model_id = \"ibm/granite-3-2-8b-instruct\"\n",
    "\n",
    "    default_params = {\n",
    "        \"max_new_tokens\": 256,\n",
    "        \"min_new_tokens\": 0,\n",
    "        \"temperature\": 0.5,\n",
    "        \"top_p\": 0.2,\n",
    "        \"top_k\": 1\n",
    "    }\n",
    "\n",
    "    if params:\n",
    "        default_params.update(params)\n",
    "\n",
    "    # Set up credentials for WatsonxLLM\n",
    "    url = \"https://us-south.ml.cloud.ibm.com\"\n",
    "    api_key = \"your api key here\"\n",
    "    project_id = \"skills-network\"\n",
    "\n",
    "    credentials = {\n",
    "        \"url\": url,\n",
    "        # \"api_key\": api_key\n",
    "        # uncomment the field above and replace the api_key with your actual Watsonx API key\n",
    "    }\n",
    "    \n",
    "    # Create LLM directly\n",
    "    granite_llm = WatsonxLLM(\n",
    "        model_id=model_id,\n",
    "        credentials=credentials,\n",
    "        project_id=project_id,\n",
    "        params=default_params\n",
    "    )\n",
    "    \n",
    "    response = granite_llm.invoke(prompt_txt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af1b273-d63c-4ab4-8931-8aac53f6f332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_model(prompt_txt, params=None):\n",
    "    \n",
    "    model_id = \"ibm/granite-3-2-8b-instruct\"\n",
    "\n",
    "    default_params = {\n",
    "        \"max_new_tokens\": 256,\n",
    "        \"min_new_tokens\": 0,\n",
    "        \"temperature\": 0.5,\n",
    "        \"top_p\": 0.2,\n",
    "        \"top_k\": 1\n",
    "    }\n",
    "\n",
    "    url = \"https://us-south.ml.cloud.ibm.com\"\n",
    "    project_id = \"skills-network\"\n",
    "    \n",
    "    granite_llm = WatsonxLLM(\n",
    "        model_id=model_id,\n",
    "        project_id=project_id,\n",
    "        url=url,\n",
    "        params=default_params\n",
    "    )\n",
    "    \n",
    "    response = granite_llm.invoke(prompt_txt)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11270cf-2321-4ab1-8d08-71627a194cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "GenParams().get_example_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97406a3e-fc14-4922-b1f3-5e27f627740a",
   "metadata": {},
   "source": [
    "# üß© Prompt Engineering\n",
    "\n",
    "**Prompt engineering** is the art and science of crafting effective inputs for Large Language Models (LLMs) to generate desired outputs.\n",
    "\n",
    "As the capabilities and scale of LLMs have grown, the importance of *how* we communicate with them has grown as well.  \n",
    "Prompt engineering involves **strategically designing prompts** that guide an AI model‚Äôs responses toward:\n",
    "\n",
    "- Specific goals  \n",
    "- Desired formats  \n",
    "- Accurate reasoning patterns  \n",
    "- Better task alignment  \n",
    "\n",
    "---\n",
    "\n",
    "## üß† In-Context Learning\n",
    "\n",
    "**In-context learning** is one of the most fascinating abilities of modern LLMs.\n",
    "\n",
    "It refers to the model‚Äôs ability to *‚Äúlearn‚Äù from examples provided directly in the prompt*, without modifying its internal weights.\n",
    "\n",
    "üí° In other words:  \n",
    "The model adapts to new tasks simply by being shown examples of what good results look like.\n",
    "\n",
    "### ‚ú® Key Advantages:\n",
    "- No fine-tuning required  \n",
    "- Instant task adaptation  \n",
    "- Works across various domains  \n",
    "- Enables few-shot and zero-shot prompting  \n",
    "\n",
    "---\n",
    "\n",
    "## üîó Combining Prompt Engineering + In-Context Learning\n",
    "\n",
    "When prompt engineering techniques are combined with the power of in-context learning, developers gain the ability to:\n",
    "\n",
    "- Create highly accurate responses  \n",
    "- Control the model‚Äôs reasoning style  \n",
    "- Achieve better consistency  \n",
    "- Guide the LLM across a wide range of tasks  \n",
    "\n",
    "This combination enables AI systems to perform tasks with **remarkable flexibility and efficiency**, often with minimal data.\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Next Steps\n",
    "\n",
    "Let‚Äôs now explore these methods in detail and learn how to apply them effectively.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0857e876-ea2d-4564-aba4-d55906e8266b",
   "metadata": {},
   "source": [
    "Basic Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987516da-f631-44f7-a514-c6897a7ee894",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max new tokens\" : 128,\n",
    "    \"min new tokens\" : 10,\n",
    "    \"temperature\" :  0.5,\n",
    "    \"top p\" : 0.2,\n",
    "    \"top k\" : 1\n",
    "}\n",
    "\n",
    "prompt = \"The  Wind is \"\n",
    "\n",
    "response = llm_model(prompt, params)\n",
    "\n",
    "print(f\"prompt: {prompt}\\n\")\n",
    "print(f\"response : {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9f9f4b-f70c-41e0-bcba-0c7534b09b0d",
   "metadata": {},
   "source": [
    "# üìù Exercise 1 ‚Äî Experimenting with Basic Prompts\n",
    "\n",
    "In this exercise, you will explore how different **simple prompt phrases** lead to different model responses.  \n",
    "Your task is to modify the input phrase and observe how the LLM continues the text.\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Try the Following Prompts\n",
    "\n",
    "Use each prompt separately and compare how the model generates content:\n",
    "\n",
    "1. **\"The future of artificial intelligence is\"**\n",
    "\n",
    "2. **\"Once upon a time in a distant galaxy\"**\n",
    "\n",
    "3. **\"The benefits of sustainable energy include\"**\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ What to Observe\n",
    "As you experiment, pay attention to:\n",
    "\n",
    "- Differences in tone and style  \n",
    "- How the model interprets each starting phrase  \n",
    "- Variations in creativity or factual writing  \n",
    "- Any patterns in structure or continuation  \n",
    "\n",
    "---\n",
    "\n",
    "## üñ•Ô∏è Sample Code Cell (Run in Notebook)\n",
    "\n",
    "```python\n",
    "prompts = [\n",
    "    \"The future of artificial intelligence is\",\n",
    "    \"Once upon a time in a distant galaxy\",\n",
    "    \"The benefits of sustainable energy include\"\n",
    "]\n",
    "\n",
    "for p in prompts:\n",
    "    print(f\"Prompt: {p}\\n\")\n",
    "    print(granite_llm.invoke(p))\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c699c6c9-5ba3-433f-a9de-b945aa34f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_new_tokens\": 128, # Try 256 or 512 for more detailed answers\n",
    "    \"min_new_tokens\": 10, # Increase to 25-50 if you want more substantial answers\n",
    "    \"temperature\": 0.5, # Controls randomness in generation (0.0-1.0)\n",
    "                       # Lower (0.1-0.3): More focused, consistent, factual responses\n",
    "                      # Higher (0.7-1.0): More creative, diverse, unpredictable outputs\n",
    "    \"top_p\": 0.2, # Nucleus sampling - considers only highest probability tokens\n",
    "                       # Lower values (0.1-0.3): More conservative, focused text\n",
    "                       # Higher values (0.7-0.9): More diverse vocabulary and ideas\n",
    "    \"top_k\": 1 # Limits token selection to top k most likely tokens\n",
    "                       # 1 = greedy decoding (always picks most likely token)\n",
    "                       # Try 40-50 for more varied outputs\n",
    "}\n",
    "\n",
    "# Compare responses to different prompts\n",
    "prompts = [\n",
    "    \"The future of artificial intelligence is\",\n",
    "    \"Once upon a time in a distant galaxy\",\n",
    "    \"The benefits of sustainable energy include\"\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    response = llm_model(prompt, params)\n",
    "    print(f\"prompt: {prompt}\\n\")\n",
    "    print(f\"response : {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6f3525-5330-4009-83ba-6bf69d1b4870",
   "metadata": {},
   "source": [
    "Zero_ Short_Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd6b77e-ccf0-4f2d-84c5-f0869a48133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Classify the following statement as true or false: \n",
    "            'The Eiffel Tower is located in Berlin.'\n",
    "\n",
    "            Answer:\n",
    "\"\"\"\n",
    "response = llm_model(prompt, params)\n",
    "print(f\"prompt: {prompt}\\n\")\n",
    "print(f\"response : {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e907e28-5291-4c83-8d15-bb60c7e33f17",
   "metadata": {},
   "source": [
    "# üìù Exercise 2 ‚Äî Creating Zero-Shot Prompts\n",
    "\n",
    "In this exercise, you will design **zero-shot prompts**‚Äîprompts that ask the model to perform a task **without providing any examples**.  \n",
    "This helps you understand how well an LLM can generalize instructions on its own.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Task 1: Classify a Movie Review  \n",
    "Write a zero-shot prompt that instructs the model to classify a movie review as **positive** or **negative**.\n",
    "\n",
    "### ‚úÖ Example Prompt (Zero-Shot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad56708-069c-4f95-9540-909eada206b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prompt for Movie Review Classification\n",
    "movie_review_prompt = \"\"\"\n",
    "Classify the following movie review as either 'positive' or 'negative'.\n",
    "\n",
    "Review: \"I was extremely disappointed by this film. The plot was predictable, the acting was wooden, and the special effects looked cheap. I can't recommend this to anyone.\"\n",
    "\n",
    "Classification:\n",
    "\"\"\"\n",
    "\n",
    "# 2. Prompt for Climate Change Paragraph Summarization\n",
    "climate_change_prompt = \"\"\"\n",
    "Summarize the following paragraph about climate change in no more than two sentences.\n",
    "\n",
    "Paragraph: \"Climate change refers to long-term shifts in temperatures and weather patterns. These shifts may be natural, but since the 1800s, human activities have been the main driver of climate change, primarily due to the burning of fossil fuels like coal, oil and gas, which produces heat-trapping gases. The consequences of climate change include more frequent and severe droughts, storms, and heat waves, rising sea levels, melting glaciers, and warming oceans which can directly impact biodiversity, agriculture, and human health.\"\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "# 3. Prompt for English to Spanish Translation\n",
    "translation_prompt = \"\"\"\n",
    "Translate the following English phrase into Spanish.\n",
    "\n",
    "English: \"I would like to order a coffee with milk and two sugars, please.\"\n",
    "\n",
    "Spanish:\n",
    "\"\"\"\n",
    "\n",
    "responses = {}\n",
    "responses[\"movie_review\"] = llm_model(movie_review_prompt)\n",
    "responses[\"climate_change\"] = llm_model(climate_change_prompt)\n",
    "responses[\"translation\"] = llm_model(translation_prompt)\n",
    "\n",
    "for prompt_type, response in responses.items():\n",
    "    print(f\"=== {prompt_type.upper()} RESPONSE ===\")\n",
    "    print(response)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bf97c8-aa78-47fa-b903-bb42f9407e14",
   "metadata": {},
   "source": [
    "One_Short_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1695f22a-1ee5-4a23-8ae4-5a1b87785a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_new_tokens\": 20,\n",
    "    \"temperature\": 0.1,\n",
    "}\n",
    "\n",
    "prompt = \"\"\"Here is an example of translating a sentence from English to French:\n",
    "\n",
    "            English: ‚ÄúHow is the weather today?‚Äù\n",
    "            French: ‚ÄúComment est le temps aujourd'hui?‚Äù\n",
    "            \n",
    "            Now, translate the following sentence from English to French:\n",
    "            \n",
    "            English: ‚ÄúWhere is the nearest supermarket?‚Äù\n",
    "            \n",
    "\"\"\"\n",
    "response = llm_model(prompt, params)\n",
    "print(f\"prompt: {prompt}\\n\")\n",
    "print(f\"response : {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febe9c9d-23b8-4bc0-9b1c-f236335e8ec8",
   "metadata": {},
   "source": [
    "# üìù Exercise 3 ‚Äî Developing One-Shot Prompts\n",
    "\n",
    "In this exercise, you will create **one-shot prompts**, where you give the model **one example** and then ask it to perform a similar task on new input.  \n",
    "This helps the model understand the pattern you expect.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úâÔ∏è Task 1: Generate a Formal Email  \n",
    "Provide **one example** of a formal email, then ask the model to write another formal email on a different topic.\n",
    "\n",
    "### ‚úÖ Example One-Shot Prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e48c3d2-4d0c-4ba2-a860-b8c40b21fea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. One-shot prompt for formal email writing\n",
    "formal_email_prompt = \"\"\"\n",
    "Here is an example of a formal email requesting information:\n",
    "\n",
    "Subject: Inquiry Regarding Product Specifications for Model XYZ-100\n",
    "\n",
    "Dear Customer Support Team,\n",
    "\n",
    "I hope this email finds you well. I am writing to request detailed specifications for your product Model XYZ-100. Specifically, I am interested in learning about its dimensions, power requirements, and compatibility with third-party accessories.\n",
    "\n",
    "Could you please provide this information at your earliest convenience? Additionally, I would appreciate any available documentation or user manuals that you could share.\n",
    "\n",
    "Thank you for your assistance in this matter.\n",
    "\n",
    "Sincerely,\n",
    "John Smith\n",
    "\n",
    "---\n",
    "\n",
    "Now, please write a formal email to a university admissions office requesting information about their application deadline and required documents for the Master's program in Computer Science:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 2. One-shot prompt for simplifying technical concepts\n",
    "technical_concept_prompt = \"\"\"\n",
    "Here is an example of explaining a technical concept in simple terms:\n",
    "\n",
    "Technical Concept: Blockchain\n",
    "Simple Explanation: A blockchain is like a digital notebook that many people have copies of. When someone writes a new entry in this notebook, everyone's copy gets updated. Once something is written, it can't be erased or changed, and everyone can see who wrote what. This makes it useful for recording important information that needs to be secure and trusted by everyone.\n",
    "\n",
    "---\n",
    "\n",
    "Now, please explain the following technical concept in simple terms:\n",
    "\n",
    "Technical Concept: Machine Learning\n",
    "Simple Explanation:\n",
    "\"\"\"\n",
    "\n",
    "# 3. One-shot prompt for keyword extraction\n",
    "keyword_extraction_prompt = \"\"\"\n",
    "Here is an example of extracting keywords from a sentence:\n",
    "\n",
    "Sentence: \"Cloud computing offers businesses flexibility, scalability, and cost-efficiency for their IT infrastructure needs.\"\n",
    "Keywords: cloud computing, flexibility, scalability, cost-efficiency, IT infrastructure\n",
    "\n",
    "---\n",
    "\n",
    "Now, please extract the main keywords from the following sentence:\n",
    "\n",
    "Sentence: \"Sustainable agriculture practices focus on biodiversity, soil health, water conservation, and reducing chemical inputs.\"\n",
    "Keywords:\n",
    "\"\"\"\n",
    "\n",
    "responses = {}\n",
    "responses[\"formal_email\"] = llm_model(formal_email_prompt)\n",
    "responses[\"technical_concept\"] = llm_model(technical_concept_prompt)\n",
    "responses[\"keyword_extraction\"] = llm_model(keyword_extraction_prompt)\n",
    "\n",
    "for prompt_type, response in responses.items():\n",
    "    print(f\"=== {prompt_type.upper()} RESPONSE ===\")\n",
    "    print(response)\n",
    "    print()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be07987-c31f-40d0-863e-5d96c7a15aba",
   "metadata": {},
   "source": [
    "Few-shot prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5ce891-c68a-42ca-b5af-f9e086331f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\n",
    "    \"max_new_tokens\": 10,\n",
    "}\n",
    "\n",
    "prompt = \"\"\"Here are few examples of classifying emotions in statements:\n",
    "\n",
    "            Statement: 'I just won my first marathon!'\n",
    "            Emotion: Joy\n",
    "            \n",
    "            Statement: 'I can't believe I lost my keys again.'\n",
    "            Emotion: Frustration\n",
    "            \n",
    "            Statement: 'My best friend is moving to another country.'\n",
    "            Emotion: Sadness\n",
    "            \n",
    "            Now, classify the emotion in the following statement:\n",
    "            Statement: 'That movie was so scary I had to cover my eyes.‚Äô\n",
    "            \n",
    "\n",
    "\"\"\"\n",
    "response = llm_model(prompt, params)\n",
    "print(f\"prompt: {prompt}\\n\")\n",
    "print(f\"response : {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f63d6ac-ca2e-49c5-a258-65e6bce37492",
   "metadata": {},
   "source": [
    "Chain-of-thought (CoT) prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf5d041-fecd-473a-8333-189a8edc1b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_new_tokens\": 512,\n",
    "    \"temperature\": 0.5,\n",
    "}\n",
    "\n",
    "prompt = \"\"\"Consider the problem: 'A store had 22 apples. They sold 15 apples today and got a new delivery of 8 apples. \n",
    "            How many apples are there now?‚Äô\n",
    "\n",
    "            Break down each step of your calculation\n",
    "\n",
    "\"\"\"\n",
    "response = llm_model(prompt, params)\n",
    "print(f\"prompt: {prompt}\\n\")\n",
    "print(f\"response : {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acd12b0-ec92-4598-aa1c-609c7e1509a8",
   "metadata": {},
   "source": [
    "# üß† Exercise 4 ‚Äî Chain-of-Thought (CoT) Prompts\n",
    "\n",
    "Use the prompts below to elicit step-by-step reasoning from the model.  \n",
    "Each prompt asks the model to list steps/reasons, evaluate them, and end with a concise final decision.\n",
    "\n",
    "---\n",
    "\n",
    "## 1) Should the student study tonight or go to a movie?\n",
    "\n",
    "### ‚úÖ CoT Prompt ‚Äî Full reasoning then verdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d28f49-2a2f-47ec-881b-473de1ad3e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Prompt for decision-making process\n",
    "decision_making_prompt = \"\"\"\n",
    "Consider this situation: A student is trying to decide whether to study tonight or go to a movie with friends. They have a test in two days.\n",
    "\n",
    "Think through this decision step-by-step, considering the pros and cons of each option, and what factors might be most important in making this choice.\n",
    "\"\"\"\n",
    "\n",
    "# 2. Prompt for explaining a process\n",
    "sandwich_making_prompt = \"\"\"\n",
    "Explain how to make a peanut butter and jelly sandwich.\n",
    "\n",
    "Break down each step of the process in detail, from gathering ingredients to finishing the sandwich.\n",
    "\"\"\"\n",
    "\n",
    "responses = {}\n",
    "responses[\"decision_making\"] = llm_model(decision_making_prompt)\n",
    "responses[\"sandwich_making\"] = llm_model(sandwich_making_prompt)\n",
    "\n",
    "for prompt_type, response in responses.items():\n",
    "    print(f\"=== {prompt_type.upper()} RESPONSE ===\")\n",
    "    print(response)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85de32ed-4fdb-4580-843d-fcc8734c4201",
   "metadata": {},
   "source": [
    "Self-consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fa2484-e5a3-4bcd-bfb9-e0eed9cee49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_new_tokens\": 512,\n",
    "}\n",
    "\n",
    "prompt = \"\"\"When I was 6, my sister was half of my age. Now I am 70, what age is my sister?\n",
    "\n",
    "            Provide three independent calculations and explanations, then determine the most consistent result.\n",
    "\n",
    "\"\"\"\n",
    "response = llm_model(prompt, params)\n",
    "print(f\"prompt: {prompt}\\n\")\n",
    "print(f\"response : {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c645e444-a185-41bd-9020-ff64c16a96c7",
   "metadata": {},
   "source": [
    "# üí° Applications of Prompting in Different Use Cases\n",
    "\n",
    "In this section, we will demonstrate how to leverage **LangChain's prompt templates** to build practical applications with **consistent, reproducible results**.\n",
    "\n",
    "Each application follows a common workflow using the **LCEL approach**:\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è LCEL Approach\n",
    "\n",
    "1. **Define the content or problem**  \n",
    "   - Identify the input data or the task to be solved.\n",
    "\n",
    "2. **Create a template with variables**  \n",
    "   - Introduce placeholders for dynamic content in the prompt.\n",
    "\n",
    "3. **Convert the template into a LangChain `PromptTemplate`**  \n",
    "   - Makes the prompt reusable and easier to manage.\n",
    "\n",
    "4. **Build a chain** using the **pipe operator (`|`)** to connect:  \n",
    "   - Input variables  \n",
    "   - Prompt template  \n",
    "   - The LLM instance  \n",
    "   - An output parser (if needed)\n",
    "\n",
    "5. **Invoke the chain with specific inputs**  \n",
    "   - Generate results by feeding actual data into the template.\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Benefits of This Structured Approach\n",
    "\n",
    "- **Reusable components:** Easily apply the same template to multiple tasks.  \n",
    "- **Consistency:** Prompts produce predictable results across different runs.  \n",
    "- **Flexibility:** Adjust parameters, input variables, and output parsing without rewriting prompts.  \n",
    "- **Scalable:** Use the same LCEL pattern across various NLP tasks and applications.  \n",
    "\n",
    "---\n",
    "\n",
    "### üìå Next Steps\n",
    "\n",
    "You will see how this pattern applies in different **use cases**, such as:\n",
    "\n",
    "- Question-Answering Bots  \n",
    "- Text Summarization Tools  \n",
    "- Translation or Paraphrasing Pipelines  \n",
    "- Keyword Extraction and Categorization  \n",
    "\n",
    "By following the LCEL workflow, you can **rapidly prototype and deploy NLP solutions** while maintaining clarity and reproducibility.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f5c3b4-5319-4420-8821-54ad8696ee23",
   "metadata": {},
   "source": [
    "Introduction to LangChain\n",
    "LangChain is a powerful framework designed to simplify the development of applications powered by language models. Built to address the challenges of working with LLMs in practical settings, LangChain provides a standardized interface for connecting models with various data sources and application environments.\n",
    "\n",
    "LangChain serves as an abstraction layer, making it easier to build complex LLM applications without handling the low-level details of model interaction. This framework has become a standard tool in the LLM ecosystem, supporting a wide range of use cases from chatbots to document analysis systems.\n",
    "\n",
    "In this section, we'll focus on LangChain's prompt template capabilities, demonstrating how they can be used to create structured, reproducible interactions with language models across different application types.\"\n",
    "\n",
    "Prompt template\n",
    "Prompt templates are a key concept in LangChain. They help translate user input and parameters into instructions for a language model. These templates can be used to guide a model's response, helping it understand the context and generate relevant and coherent language-based outputs.\n",
    "\n",
    "A prompt template acts as a reusable structure for generating prompts with dynamic values. It allows you to define a consistent format while leaving placeholders for variables that change with each use case. This approach makes prompting more systematic and maintainable, especially when working with complex applications.\n",
    "\n",
    "Modern LangChain (as of 2025) offers two main approaches to working with templates:\n",
    "\n",
    "The traditional LLMChain approach\n",
    "The newer LangChain Expression Language (LCEL) pattern using the pipe operator | for more flexible composition\n",
    "LCEL has become the recommended pattern for building LangChain applications as it offers better composability, clearer visualization of data flow, and more flexibility when constructing complex chains.\n",
    "\n",
    "To use a prompt template with LCEL, you typically follow these steps:\n",
    "\n",
    "Define your template with variables in curly braces {}\n",
    "Create a PromptTemplate instance\n",
    "Build a chain using the pipe operator | to connect components\n",
    "Invoke the chain with your input values\n",
    "Let's initialize an LLM first, then demonstrate this approach. In this section, we will use the model meta-llama/llama-3-3-70b-instruct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ea0934-f49f-4507-8a1c-d2cd24d9131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/llama-3-3-70b-instruct\"\n",
    "\n",
    "parameters = {\n",
    "    GenParams.MAX_NEW_TOKENS: 256,  # this controls the maximum number of tokens in the generated output\n",
    "    GenParams.TEMPERATURE: 0.5, # this randomness or creativity of the model's responses\n",
    "}\n",
    "\n",
    "url = \"https://us-south.ml.cloud.ibm.com\"\n",
    "project_id = \"skills-network\"\n",
    "\n",
    "llm = WatsonxLLM(\n",
    "        model_id=model_id,\n",
    "        url=url,\n",
    "        project_id=project_id,\n",
    "        params=parameters\n",
    "    )\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7cd4cf-4ea6-4597-b130-9f694327acf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Tell me a {adjective} joke about {content}.\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2864537a-f727-499e-b1b0-8ba4a8aa7d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.format(adjective=\"funny\", content=\"chickens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1666378e-06bd-4e1d-a1c9-9ac6e96c4a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# Define a function to ensure proper formatting\n",
    "def format_prompt(variables):\n",
    "    return prompt.format(**variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cec7c1a-d6bb-47ec-b7df-2a8e7bd7496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the chain with explicit formatting\n",
    "joke_chain = (\n",
    "    RunnableLambda(format_prompt)\n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "response = joke_chain.invoke({\"adjective\": \"funny\", \"content\": \"chickens\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a104865-7344-4d30-8611-41e28852aef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = joke_chain.invoke({\"adjective\": \"sad\", \"content\": \"fish\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cea0b2f-99bf-4a27-b04f-bbf93d873e9b",
   "metadata": {},
   "source": [
    "Text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e785f4-be8f-4295-8c67-a22aedddae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "    The rapid advancement of technology in the 21st century has transformed various industries, including healthcare, education, and transportation. \n",
    "    Innovations such as artificial intelligence, machine learning, and the Internet of Things have revolutionized how we approach everyday tasks and complex problems. \n",
    "    For instance, AI-powered diagnostic tools are improving the accuracy and speed of medical diagnoses, while smart transportation systems are making cities more efficient and reducing traffic congestion. \n",
    "    Moreover, online learning platforms are making education more accessible to people around the world, breaking down geographical and financial barriers. \n",
    "    These technological developments are not only enhancing productivity but also contributing to a more interconnected and informed society.\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"Summarize the {content} in one sentence.\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create the LCEL chain\n",
    "summarize_chain = (\n",
    "    RunnableLambda(format_prompt)\n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "summary = summarize_chain.invoke({\"content\": content})\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d55ef58-b992-4aa5-9820-8b7c5334bb98",
   "metadata": {},
   "source": [
    "Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee78b94-f5b1-4b5b-b4f3-3409960b8515",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "    The concert last night was an exhilarating experience with outstanding performances by all artists.\n",
    "\"\"\"\n",
    "\n",
    "categories = \"Entertainment, Food and Dining, Technology, Literature, Music.\"\n",
    "\n",
    "template = \"\"\"\n",
    "    Classify the {text} into one of the {categories}.\n",
    "    \n",
    "    Category:\n",
    "    \n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create the LCEL chain\n",
    "classification_chain = (\n",
    "    RunnableLambda(format_prompt)\n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "category = classification_chain.invoke({\"text\": text, \"categories\": categories})\n",
    "print(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19756a47-d8b6-4752-98fb-04e2bbef7d67",
   "metadata": {},
   "source": [
    "Code generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39acbee3-11ec-4847-aae2-6b04a6c29a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"\"\"\n",
    "    Retrieve the names and email addresses of all customers from the 'customers' table who have made a purchase in the last 30 days. \n",
    "    The table 'purchases' contains a column 'purchase_date'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "    Generate an SQL query based on the {description}\n",
    "    \n",
    "    SQL Query:\n",
    "    \n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create the LCEL chain\n",
    "sql_generation_chain = (\n",
    "    RunnableLambda(format_prompt) \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "sql_query = sql_generation_chain.invoke({\"description\": description})\n",
    "print(sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1364fbe-56d2-4584-9d2f-cf68ded516db",
   "metadata": {},
   "source": [
    "Role playing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7795c121-667c-40ba-83bd-31c839a8e934",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = \"\"\"\n",
    "    Dungeon & Dragons game master\n",
    "\"\"\"\n",
    "\n",
    "tone = \"engaging and immersive\"\n",
    "\n",
    "template = \"\"\"\n",
    "    You are an expert {role}. I have this question {question}. I would like our conversation to be {tone}.\n",
    "    \n",
    "    Answer:\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create the LCEL chain\n",
    "roleplay_chain = (\n",
    "    RunnableLambda(format_prompt)\n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Create an interactive chat loop\n",
    "while True:\n",
    "    query = input(\"Question: \")\n",
    "    \n",
    "    if query.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
    "        print(\"Answer: Goodbye!\")\n",
    "        break\n",
    "        \n",
    "    response = roleplay_chain.invoke({\"role\": role, \"question\": query, \"tone\": tone})\n",
    "    print(\"Answer: \", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff6feab-2c49-4133-b8a9-92c6d7054e03",
   "metadata": {},
   "source": [
    "Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f6b7cc-fc10-41db-bba1-bacd07fab778",
   "metadata": {},
   "source": [
    "Create an LCEL Chain with Custom Formatting\n",
    "\n",
    "In this exercise, you'll create your own LCEL chain that uses prompt templates to build a custom application.\n",
    "\n",
    "Task: Create a product review analyzer that can:\n",
    "\n",
    "Identify the sentiment (positive, negative, or neutral).\n",
    "Extract mentioned product features.\n",
    "Provide a one-sentence summary of the review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83b356d-c656-48d1-b962-83799c4e7b5e",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "Create a prompt template with placeholders for the review text.\n",
    "Build an LCEL chain that formats your prompt properly.\n",
    "Process the sample reviews and display the results.\n",
    "Try modifying the chain to change the output format.\n",
    "Sample input:\n",
    "\n",
    "reviews = [\n",
    "    \"I love this smartphone! The camera quality is exceptional and the battery lasts all day. The only downside is that it heats up a bit during gaming.\",\n",
    "    \"This laptop is terrible. It's slow, crashes frequently, and the keyboard stopped working after just two months. Customer service was unhelpful.\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad32272b-d3df-4d50-aa4f-42688d0b0076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "model_id = \"meta-llama/llama-3-3-70b-instruct\"\n",
    "\n",
    "parameters = {\n",
    "    GenParams.MAX_NEW_TOKENS: 512,  # this controls the maximum number of tokens in the generated output\n",
    "    GenParams.TEMPERATURE: 0.2, # this randomness or creativity of the model's responses\n",
    "}\n",
    "\n",
    "url = \"https://us-south.ml.cloud.ibm.com\"\n",
    "project_id = \"skills-network\"\n",
    "\n",
    "llm = WatsonxLLM(\n",
    "        model_id=model_id,\n",
    "        url=url,\n",
    "        project_id=project_id,\n",
    "        params=parameters\n",
    "    )\n",
    "\n",
    "# Create the prompt template\n",
    "template = \"\"\"\n",
    "Analyze the following product review:\n",
    "\"{review}\"\n",
    "\n",
    "Provide your analysis in the following format:\n",
    "- Sentiment: (positive, negative, or neutral)\n",
    "- Key Features Mentioned: (list the product features mentioned)\n",
    "- Summary: (one-sentence summary)\n",
    "\"\"\"\n",
    "\n",
    "product_review_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create a formatting function\n",
    "def format_review_prompt(variables):\n",
    "    return product_review_prompt.format(**variables)\n",
    "\n",
    "# Build the LCEL chain\n",
    "review_analysis_chain = (\n",
    "    RunnableLambda(format_review_prompt)\n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Process the reviews\n",
    "reviews = [\n",
    "    \"I love this smartphone! The camera quality is exceptional and the battery lasts all day. The only downside is that it heats up a bit during gaming.\",\n",
    "    \"This laptop is terrible. It's slow, crashes frequently, and the keyboard stopped working after just two months. Customer service was unhelpful.\"\n",
    "]\n",
    "\n",
    "for i, review in enumerate(reviews):\n",
    "    print(f\"==== Review #{i+1} ====\")\n",
    "    result = review_analysis_chain.invoke({\"review\": review})\n",
    "    print(result)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43fb6b1-2b31-46cd-8d84-442cb86f8371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f8c86f-b3f3-4bfc-9add-03e279e808d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e138aad3-db15-4b73-a582-2ccdfb8a1d99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869a3dbf-a3ce-4e5d-9a41-dae1b9db7288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
